{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASAM: Sentiment Analysis, Data Acquisition & Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "import tweepy\n",
    "import twitter\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = Path('/Users/alejandroarrya/Desktop/Ironhack/DAPTMX/keys/twitter_keys.env')\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>ISO_TA</th>\n",
       "      <th>Score_TA</th>\n",
       "      <th>Status_TA</th>\n",
       "      <th>Last Update_TA</th>\n",
       "      <th>Source_TA</th>\n",
       "      <th>Score_DOS</th>\n",
       "      <th>Status_DOS</th>\n",
       "      <th>Last Update_DOS</th>\n",
       "      <th>Source_DOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Do Not Travel</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>https://www.travel-advisory.info/afghanistan</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Do Not Travel</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>http://travel.state.gov/content/travel/en/trav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>AL</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Exercise Normal Precautions</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>https://www.travel-advisory.info/albania</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Exercise Normal Precautions</td>\n",
       "      <td>2019-07-10</td>\n",
       "      <td>http://travel.state.gov/content/travel/en/trav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "      <td>2.8</td>\n",
       "      <td>Exercised Increased Caution</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>https://www.travel-advisory.info/algeria</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Exercise Increased Caution</td>\n",
       "      <td>2019-04-09</td>\n",
       "      <td>http://travel.state.gov/content/travel/en/trav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>AD</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Exercise Normal Precautions</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>https://www.travel-advisory.info/andorra</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Exercise Normal Precautions</td>\n",
       "      <td>2019-08-27</td>\n",
       "      <td>http://travel.state.gov/content/travel/en/trav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AO</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Exercise Normal Precautions</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>https://www.travel-advisory.info/angola</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Exercise Normal Precautions</td>\n",
       "      <td>2019-04-09</td>\n",
       "      <td>http://travel.state.gov/content/travel/en/trav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name ISO_TA  Score_TA                    Status_TA Last Update_TA  \\\n",
       "0  Afghanistan     AF       5.0                Do Not Travel     2020-03-11   \n",
       "1      Albania     AL       1.5  Exercise Normal Precautions     2020-03-11   \n",
       "2      Algeria     DZ       2.8  Exercised Increased Caution     2020-03-11   \n",
       "3      Andorra     AD       1.3  Exercise Normal Precautions     2020-03-11   \n",
       "4       Angola     AO       2.0  Exercise Normal Precautions     2020-03-11   \n",
       "\n",
       "                                      Source_TA  Score_DOS  \\\n",
       "0  https://www.travel-advisory.info/afghanistan        4.0   \n",
       "1      https://www.travel-advisory.info/albania        1.0   \n",
       "2      https://www.travel-advisory.info/algeria        2.0   \n",
       "3      https://www.travel-advisory.info/andorra        1.0   \n",
       "4       https://www.travel-advisory.info/angola        1.0   \n",
       "\n",
       "                    Status_DOS Last Update_DOS  \\\n",
       "0                Do Not Travel      2019-10-22   \n",
       "1  Exercise Normal Precautions      2019-07-10   \n",
       "2   Exercise Increased Caution      2019-04-09   \n",
       "3  Exercise Normal Precautions      2019-08-27   \n",
       "4  Exercise Normal Precautions      2019-04-09   \n",
       "\n",
       "                                          Source_DOS  \n",
       "0  http://travel.state.gov/content/travel/en/trav...  \n",
       "1  http://travel.state.gov/content/travel/en/trav...  \n",
       "2  http://travel.state.gov/content/travel/en/trav...  \n",
       "3  http://travel.state.gov/content/travel/en/trav...  \n",
       "4  http://travel.state.gov/content/travel/en/trav...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common = pd.read_csv('./data/dos_ta_merged.csv', index_col=0)\n",
    "common.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Authenticate, Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = os.getenv('CONSUMER_KEY')\n",
    "CONSUMER_SECRET = os.getenv('CONSUMER_SECRET')\n",
    "ACCESS_TOKEN = os.getenv('ACCESS_TOKEN')\n",
    "ACCESS_TOKEN_SECRET = os.getenv('ACCESS_TOKEN_SECRET')\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "tw = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication OK\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tw.verify_credentials()\n",
    "    print(\"Authentication OK\")\n",
    "except:\n",
    "    print(\"Error during authentication\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = 'from:USATODAY OR from:WSJ OR from:nytimes OR from:washingtonpost OR from:latimes OR from:chicagotribune OR from:guardian OR from:thetimes OR from:Telegraph OR from:FinancialTimes OR from:SCMPNews OR from:timesofindia OR from:japantimes OR from:smh OR from:dwnews OR from:BBCWorld OR from:AP OR from:globeandmail OR from:Reuters'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 554\n"
     ]
    }
   ],
   "source": [
    "tw_corpus = pd.DataFrame(columns=['Tweets','Name'])\n",
    "\n",
    "for name in common.Name.values:\n",
    "    search_query = f'{name} {str(sources)}'\n",
    "    corpus = tw.search(q=search_query, count=100,\n",
    "                       result_type = \"recent\",\n",
    "                       lang = \"en\",\n",
    "                       include_entities=False,\n",
    "                       tweet_mode='extended')\n",
    "    tw_corpus.append([{'Tweets':[tweet.full_text for tweet in corpus]},{'Name': name}], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_corpus['Name'] = tw_corpus['Name'].shift(-1)\n",
    "tw_corpus = tw_corpus.dropna(axis=0,how='all')\n",
    "tw_corpus = tw_corpus.drop(['level_0','index'], axis=1)\n",
    "tw_corpus = pd.DataFrame(tw_corpus.Tweets.tolist(), index=tw_corpus.Name).stack().reset_index(level=1, drop=True).reset_index(name='Tweets')[['Tweets','Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    text = re.sub(r'RT[\\s]+', '', text)\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_corpus['Tweets'] = tw_corpus['Tweets'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The coronavirus doesn’t fit the templates of 9...</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The man with the gun in his hand had jail time...</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pakistan's interior ministry said it will clos...</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan’s Kashmir Fallout\\n\\nHow will like...</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan is preparing to release 1,500 Tali...</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Afghan President Ashraf Ghani signed a decree ...</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Taliban have overtaken Islamic State as th...</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>President Ashraf Ghani of Afghanistan ordered ...</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghan government to release Taliban prisoners...</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hundreds of British troops will be withdrawn f...</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets         Name\n",
       "0  The coronavirus doesn’t fit the templates of 9...  Afghanistan\n",
       "1  The man with the gun in his hand had jail time...  Afghanistan\n",
       "2  Pakistan's interior ministry said it will clos...  Afghanistan\n",
       "3  Afghanistan’s Kashmir Fallout\\n\\nHow will like...  Afghanistan\n",
       "4  Afghanistan is preparing to release 1,500 Tali...  Afghanistan\n",
       "5  Afghan President Ashraf Ghani signed a decree ...  Afghanistan\n",
       "6  The Taliban have overtaken Islamic State as th...  Afghanistan\n",
       "7  President Ashraf Ghani of Afghanistan ordered ...  Afghanistan\n",
       "8  Afghan government to release Taliban prisoners...  Afghanistan\n",
       "9  Hundreds of British troops will be withdrawn f...  Afghanistan"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_corpus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])\n",
    "\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])\n",
    "\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  \n",
    "         u\"\\U0001F300-\\U0001F5FF\"  \n",
    "         u\"\\U0001F680-\\U0001F6FF\"  \n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)\n",
    "\n",
    "emoticons = emoticons_happy.union(emoticons_sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    " \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(tweet)\n",
    "    \n",
    "    tweet = re.sub(r':', '', tweet)\n",
    "    tweet = re.sub(r'‚Ä¶', '', tweet)\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "    tweet = emoji_pattern.sub(r'', tweet)\n",
    "    \n",
    "    filtered_tweet = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_tweet = []\n",
    "    \n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words and w not in emoticons and w not in string.punctuation:\n",
    "            filtered_tweet.append(w)\n",
    "    \n",
    "    return ' '.join(filtered_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_corpus['Tweets'] = tw_corpus['Tweets'].apply(clean_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_corpus.to_csv('/Users/alejandroarrya/Desktop/Ironhack/DAPTMX/final_project/TASAM_final_project/data/tw_corpus.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
